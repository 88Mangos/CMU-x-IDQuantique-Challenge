{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464d9248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package Imports - feel free to add what you think might be useful! \n",
    "import torch\n",
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bd5b50",
   "metadata": {},
   "source": [
    "## Task 1: Playing with Pseudo-Randomness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af55384",
   "metadata": {},
   "source": [
    "### Part A: Implement LCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1381c390",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Linear_Congruential_Generator(seed, multipler, increment, modulus):\n",
    "    sequence = []\n",
    "    pass # TODO: implement the LCG here!\n",
    "    return sequence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edfacb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass # TODO: run your generator for at least 10e5 steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4b6af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass # TODO: plot a histogram of the generated numbers to visualize distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86ca03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass # TODO: ensure at least one parameter set satisfies the Hull-Dobell Theorem and demonstrates a full-period LCG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee04daba",
   "metadata": {},
   "source": [
    "### Part B: Randomness over Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ad0145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeEntropy(X):\n",
    "    \"\"\" \n",
    "    You can pass in the random variable X in whatever form you choose.\n",
    "    One way to represent a random variable is as a dictionary, \n",
    "    where each (key, value) pair represents an outcome x \n",
    "    and its probability P(X = x)\n",
    "\n",
    "    Hint: NumPy might be helpful here!\n",
    "    \"\"\"\n",
    "    pass # TODO: copmute Shannon Entropy or Min Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7ed2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "1. fix a short seed value for each LCG \n",
    "(no more than 2^10 possible values for the seed)\n",
    "\n",
    "2. Over a long LCG sequence (at least 10^6 samples),\n",
    "as the generator produces values, treat the sequence of outputs \n",
    "up to each step as a growing empirical distribution.\n",
    "\n",
    "3. At regular intervals (e.g., every 1000 iterations), \n",
    "compute the Shannon Entropy or Min-Entropy \n",
    "of the current sample distribution.\n",
    "\n",
    "Hint: We've already imported matplotlib for you, \n",
    "though any plotting package will do the trick.\n",
    "\"\"\"\n",
    "pass # TODO: Plot how the Shannon Entropy or Min-Entropy evolves with the number of iterations for each LCG configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7e9368",
   "metadata": {},
   "source": [
    "### Part C: Periodicity and Autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52c340e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass # TODO: Similarly, using your previous LCGs generate a long LCG sequence (at least 10^6 samples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3c25a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass # TODO: For each sequence compute the period and compute the autocorrelation over multiple lags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73667bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass # TODO: Provide line plots of autocorrelation rho_k against the lag k "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e04feb2",
   "metadata": {},
   "source": [
    "### Part D: Breaking the Illusion of Randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1156defb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass # TODO: Apply statistical tests: either chi-squared or Kolmogov-Smirnov to test if your generated random number sequences are random by comparing them to uniform distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d78b73",
   "metadata": {},
   "source": [
    "### Bonus Task:\n",
    "Train a light-weight model (small-neural net or decision tree) to predict the next number in your random number sequence. Now try implementing at least two other more robust PRNGs from the list below:\n",
    "- XOR-Shift Generator\n",
    "- Permuted Congruential Generator (PCG) \n",
    "- SplitMix64 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba7b852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may want to import these packages, though feel free to import anything else you need\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "\n",
    "import tensorflow as tf \n",
    "import keras \n",
    "\n",
    "import sklearn"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
